{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3.2Sprk上FP-Growth算法实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.fpm import FPGrowth\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['牛奶'] : 4\n",
      "['牛奶', '纸尿裤'] : 3\n",
      "['牛奶', '纸尿裤', '奶酪'] : 3\n",
      "['牛奶', '奶酪'] : 4\n",
      "['饮料'] : 4\n",
      "['饮料', '牛奶'] : 3\n",
      "['饮料', '牛奶', '奶酪'] : 3\n",
      "['饮料', '纸尿裤'] : 3\n",
      "['饮料', '奶酪'] : 3\n",
      "['蜂蜜'] : 3\n",
      "['奶酪'] : 5\n",
      "['啤酒'] : 3\n",
      "['啤酒', '纸尿裤'] : 3\n",
      "['纸尿裤'] : 5\n",
      "['纸尿裤', '奶酪'] : 4\n",
      "['面包'] : 4\n",
      "['面包', '牛奶'] : 3\n",
      "['面包', '牛奶', '奶酪'] : 3\n",
      "['面包', '纸尿裤'] : 3\n",
      "['面包', '纸尿裤', '奶酪'] : 3\n",
      "['面包', '奶酪'] : 4\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='FPGrowth')\n",
    "data = sc.textFile('fpgrowth.txt')\n",
    "transactions = data.map(lambda line:line.strip().split(',')[1:])\n",
    "minSupport = 0.5\n",
    "numPartitions = 2\n",
    "model = FPGrowth.train(transactions,minSupport,numPartitions)\n",
    "result = model.freqItemsets().collect()\n",
    "for fi in result:   \n",
    "    print(str(fi.items).replace('u\\'','\\'').encode('unicode-escape').decode(\"unicode-escape\"),\":\",fi.freq)\n",
    "sc.stop()                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.session.SparkSession'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "print(type(spark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|items                                    |\n",
      "+-----------------------------------------+\n",
      "|[1, 饮料, 鸡腿, 蜂蜜, 面包, 牛奶, 奶酪]  |\n",
      "|[2, 面包, 牛奶, 奶酪, 鸡蛋, 纸尿裤, 蜂蜜]|\n",
      "|[3, 啤酒, 纸尿裤, 罐头, 面包, 奶酪, 果酱]|\n",
      "|[4, 啤酒, 纸尿裤, 饮料, 鸡腿, 牛奶, 奶酪]|\n",
      "|[5, 啤酒, 纸尿裤, 饮料, 蜂蜜]            |\n",
      "|[6, 饮料, 纸尿裤, 果酱, 面包, 牛奶, 奶酪]|\n",
      "+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = (spark.read\n",
    "    .text(\"fpgrowth.txt\")\n",
    "    .select(split(\"value\", \",\").alias(\"items\")))\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               items|freq|\n",
      "+--------------------+----+\n",
      "|              [牛奶]|   4|\n",
      "|      [牛奶, 纸尿裤]|   3|\n",
      "|[牛奶, 纸尿裤, 奶酪]|   3|\n",
      "|        [牛奶, 奶酪]|   4|\n",
      "|              [啤酒]|   3|\n",
      "|      [啤酒, 纸尿裤]|   3|\n",
      "|              [饮料]|   4|\n",
      "|        [饮料, 牛奶]|   3|\n",
      "|  [饮料, 牛奶, 奶酪]|   3|\n",
      "|      [饮料, 纸尿裤]|   3|\n",
      "|        [饮料, 奶酪]|   3|\n",
      "|            [纸尿裤]|   5|\n",
      "|      [纸尿裤, 奶酪]|   4|\n",
      "|              [面包]|   4|\n",
      "|        [面包, 牛奶]|   3|\n",
      "|  [面包, 牛奶, 奶酪]|   3|\n",
      "|      [面包, 纸尿裤]|   3|\n",
      "|[面包, 纸尿裤, 奶酪]|   3|\n",
      "|        [面包, 奶酪]|   4|\n",
      "|              [蜂蜜]|   3|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+----------+----------+------------------+\n",
      "|    antecedent|consequent|confidence|              lift|\n",
      "+--------------+----------+----------+------------------+\n",
      "|[纸尿裤, 奶酪]|    [牛奶]|      0.75|             1.125|\n",
      "|[纸尿裤, 奶酪]|    [面包]|      0.75|             1.125|\n",
      "|  [牛奶, 奶酪]|  [纸尿裤]|      0.75|0.8999999999999999|\n",
      "|  [牛奶, 奶酪]|    [饮料]|      0.75|             1.125|\n",
      "|  [牛奶, 奶酪]|    [面包]|      0.75|             1.125|\n",
      "|        [啤酒]|  [纸尿裤]|       1.0|               1.2|\n",
      "|        [饮料]|    [牛奶]|      0.75|             1.125|\n",
      "|        [饮料]|  [纸尿裤]|      0.75|0.8999999999999999|\n",
      "|        [饮料]|    [奶酪]|      0.75|0.8999999999999999|\n",
      "|        [牛奶]|  [纸尿裤]|      0.75|0.8999999999999999|\n",
      "|        [牛奶]|    [奶酪]|       1.0|               1.2|\n",
      "|        [牛奶]|    [饮料]|      0.75|             1.125|\n",
      "|        [牛奶]|    [面包]|      0.75|             1.125|\n",
      "|  [饮料, 奶酪]|    [牛奶]|       1.0|               1.5|\n",
      "|        [面包]|    [牛奶]|      0.75|             1.125|\n",
      "|        [面包]|  [纸尿裤]|      0.75|0.8999999999999999|\n",
      "|        [面包]|    [奶酪]|       1.0|               1.2|\n",
      "|  [面包, 牛奶]|    [奶酪]|       1.0|               1.2|\n",
      "|  [面包, 奶酪]|    [牛奶]|      0.75|             1.125|\n",
      "|  [面包, 奶酪]|  [纸尿裤]|      0.75|0.8999999999999999|\n",
      "+--------------+----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='FPGrowth')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "data = (spark.read\n",
    "    .text(\"fpgrowth.txt\")\n",
    "    .select(split(\"value\", \",\").alias(\"items\")))\n",
    "\n",
    "fp = FPGrowth(minSupport=0.5, minConfidence=0.7)\n",
    "fpm = fp.fit(data)\n",
    "fpm.freqItemsets.show()\n",
    "fpm.associationRules.show()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P83有关天气情况和能否进行户外活动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.session.SparkSession'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "print(type(spark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|items                                  |\n",
      "+---------------------------------------+\n",
      "|[1, sunny, hot, high, FALSE, no]       |\n",
      "|[2, sunny, hot, high, TRUE, no]        |\n",
      "|[3, overcase, hot, high, FALSE, yes]   |\n",
      "|[4, rain, mild, high, FALSE, yes]      |\n",
      "|[5, rain, cool, normal, FALSE, yes]    |\n",
      "|[6, rain, cool, normal, TRUE, no]      |\n",
      "|[7, overcase, cool, normal, TRUE, yes] |\n",
      "|[8, sunny, mild, high, FALSE, no]      |\n",
      "|[9, sunny, cool, normal, FALSE, yes]   |\n",
      "|[10, rain, mild, normal, FALSE, yes]   |\n",
      "|[11, sunny, mild, normal, TRUE, yes]   |\n",
      "|[12, overcase, mild, high, TRUE, yes]  |\n",
      "|[13, overcase, hot, normal, FALSE, yes]|\n",
      "|[14, rain, mild, high, TRUE, no]       |\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = (spark.read\n",
    "    .text(\"weather.txt\")\n",
    "    .select(split(\"value\", \",\").alias(\"items\")))\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+\n",
      "|            items|freq|\n",
      "+-----------------+----+\n",
      "|          [sunny]|   5|\n",
      "|    [sunny, high]|   3|\n",
      "|      [sunny, no]|   3|\n",
      "|[sunny, no, high]|   3|\n",
      "|   [sunny, FALSE]|   3|\n",
      "|            [hot]|   4|\n",
      "|      [hot, high]|   3|\n",
      "|     [hot, FALSE]|   3|\n",
      "|           [high]|   7|\n",
      "|    [high, FALSE]|   4|\n",
      "|      [high, yes]|   3|\n",
      "|           [TRUE]|   6|\n",
      "|     [TRUE, high]|   3|\n",
      "|     [TRUE, mild]|   3|\n",
      "|   [TRUE, normal]|   3|\n",
      "|      [TRUE, yes]|   3|\n",
      "|           [mild]|   6|\n",
      "|     [mild, high]|   4|\n",
      "|    [mild, FALSE]|   3|\n",
      "|      [mild, yes]|   4|\n",
      "+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+----------+-------------------+------------------+\n",
      "| antecedent|consequent|         confidence|              lift|\n",
      "+-----------+----------+-------------------+------------------+\n",
      "|    [FALSE]|   [sunny]|              0.375|             1.125|\n",
      "|    [FALSE]|     [hot]|              0.375|           1.40625|\n",
      "|    [FALSE]|    [high]|                0.5|1.0714285714285714|\n",
      "|    [FALSE]|    [mild]|              0.375|            0.9375|\n",
      "|    [FALSE]|     [yes]|               0.75|              1.25|\n",
      "|    [FALSE]|  [normal]|                0.5|1.0714285714285714|\n",
      "|    [FALSE]|    [rain]|              0.375|             1.125|\n",
      "|[sunny, no]|    [high]|                1.0| 2.142857142857143|\n",
      "|       [no]|   [sunny]|                0.6|               1.8|\n",
      "|       [no]|    [high]|                0.8|1.7142857142857144|\n",
      "|       [no]|    [TRUE]|                0.6|1.4999999999999998|\n",
      "|   [normal]|    [TRUE]|0.42857142857142855|1.0714285714285714|\n",
      "|   [normal]|    [cool]| 0.5714285714285714| 2.142857142857143|\n",
      "|   [normal]|   [FALSE]| 0.5714285714285714|1.0714285714285714|\n",
      "|   [normal]|     [yes]| 0.8571428571428571|1.4285714285714286|\n",
      "|   [normal]|    [rain]|0.42857142857142855|1.2857142857142858|\n",
      "|[rain, yes]|   [FALSE]|                1.0|             1.875|\n",
      "|    [sunny]|    [high]|                0.6|1.2857142857142856|\n",
      "|    [sunny]|      [no]|                0.6|               1.8|\n",
      "|    [sunny]|   [FALSE]|                0.6|             1.125|\n",
      "+-----------+----------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='Weather')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "data = (spark.read\n",
    "    .text(\"weather.txt\")\n",
    "    .select(split(\"value\", \",\").alias(\"items\")))\n",
    "\n",
    "fp = FPGrowth(minSupport=0.2, minConfidence=0.3)\n",
    "fpm = fp.fit(data)\n",
    "fpm.freqItemsets.show()\n",
    "fpm.associationRules.show()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FPGrowthModel' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e7c44e64fc2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFPGrowth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminSupport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminConfidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfpm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mfpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreqItemsets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mfpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massociationRules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FPGrowthModel' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='Weather')\n",
    "spark = SparkSession(sc)\n",
    "a = []\n",
    "data = (spark.read\n",
    "    .text(\"weather.txt\")\n",
    "    .select(split(\"value\", \",\").alias(\"items\")))\n",
    "\n",
    "fp = FPGrowth(minSupport=0.2, minConfidence=0.3)\n",
    "fpm = fp.fit(data)\n",
    "fpm.freqItemsets.show(50)\n",
    "fpm.associationRules.show()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.2 PrefixSpan算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreqSequence(sequence=[['e']], freq=3)\n",
      "FreqSequence(sequence=[['b']], freq=4)\n",
      "FreqSequence(sequence=[['f']], freq=3)\n",
      "FreqSequence(sequence=[['c']], freq=4)\n",
      "FreqSequence(sequence=[['d']], freq=3)\n",
      "FreqSequence(sequence=[['a']], freq=4)\n",
      "FreqSequence(sequence=[['c'], ['b']], freq=3)\n",
      "FreqSequence(sequence=[['c'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['c'], ['c']], freq=3)\n",
      "FreqSequence(sequence=[['a'], ['b']], freq=4)\n",
      "FreqSequence(sequence=[['a'], ['b', 'c']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['b', 'c'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['b'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['b'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['c']], freq=4)\n",
      "FreqSequence(sequence=[['a'], ['c'], ['b']], freq=3)\n",
      "FreqSequence(sequence=[['a'], ['c'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['c'], ['c']], freq=3)\n",
      "FreqSequence(sequence=[['a'], ['d']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['d'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['a'], ['f']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'c']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'c'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'a']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'a'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'a'], ['d']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'a'], ['d'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['b', 'a'], ['f']], freq=2)\n",
      "FreqSequence(sequence=[['b'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['b'], ['c']], freq=3)\n",
      "FreqSequence(sequence=[['b'], ['d']], freq=2)\n",
      "FreqSequence(sequence=[['b'], ['d'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['b'], ['f']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['b'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['a']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['a'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['a'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['a'], ['c'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['c'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['f']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['f'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['f'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['e'], ['f'], ['c'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['f'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['f'], ['b'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['f'], ['c']], freq=2)\n",
      "FreqSequence(sequence=[['f'], ['c'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['d'], ['b']], freq=2)\n",
      "FreqSequence(sequence=[['d'], ['c']], freq=3)\n",
      "FreqSequence(sequence=[['d'], ['c'], ['b']], freq=2)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.fpm import PrefixSpan\n",
    "from pyspark import SparkContext\n",
    "if __name__ == \"__main__\":\n",
    "    data = [\n",
    "        [[\"a\"],[\"a\",\"b\",\"c\"],[\"a\",\"c\"],[\"d\"],[\"c\",\"f\"]],\n",
    "        [[\"a\",\"d\"],[\"c\"],[\"b\",\"c\"],[\"a\",\"e\"]],\n",
    "        [[\"e\",\"f\"],[\"a\",\"b\"],[\"d\",\"f\"],[\"c\"],[\"b\"]],\n",
    "        [[\"e\"],[\"g\"],[\"a\",\"f\"],[\"c\"],[\"b\"],[\"c\"]]\n",
    "    ]\n",
    "    sc = SparkContext()\n",
    "    rdd = sc.parallelize(data,2)\n",
    "    model = PrefixSpan.train(rdd, 0.5, 4)\n",
    "    result = (model.freqSequences().collect())\n",
    "    sorted(result)\n",
    "    for fi in result:\n",
    "        print(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['a']]\n",
      "[['a', 'b']]\n",
      "[['a'], ['a']]\n",
      "[['a'], ['b']]\n",
      "[['a'], ['c']]\n",
      "[['a'], ['d']]\n",
      "[['a'], ['f']]\n",
      "[['a', 'b'], ['c']]\n",
      "[['a', 'b'], ['d']]\n",
      "[['a', 'b'], ['f']]\n",
      "[['a', 'b'], ['d'], ['c']]\n",
      "[['a'], ['b', 'c']]\n",
      "[['a'], ['b'], ['a']]\n",
      "[['a'], ['b'], ['c']]\n",
      "[['a'], ['b', 'c'], ['a']]\n",
      "[['a'], ['c'], ['a']]\n",
      "[['a'], ['c'], ['b']]\n",
      "[['a'], ['c'], ['c']]\n",
      "[['a'], ['d'], ['c']]\n",
      "b 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['b']]\n",
      "[['b', 'c']]\n",
      "[['b'], ['a']]\n",
      "[['b'], ['c']]\n",
      "[['b'], ['d']]\n",
      "[['b'], ['f']]\n",
      "[['b', 'c'], ['a']]\n",
      "[['b'], ['d'], ['c']]\n",
      "c 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['c']]\n",
      "[['c'], ['a']]\n",
      "[['c'], ['b']]\n",
      "[['c'], ['c']]\n",
      "d 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['d']]\n",
      "[['d'], ['b']]\n",
      "[['d'], ['c']]\n",
      "[['d'], ['c'], ['b']]\n",
      "e 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['e']]\n",
      "[['e'], ['a']]\n",
      "[['e'], ['b']]\n",
      "[['e'], ['c']]\n",
      "[['e'], ['f']]\n",
      "[['e'], ['a'], ['b']]\n",
      "[['e'], ['a'], ['c']]\n",
      "[['e'], ['a'], ['c'], ['b']]\n",
      "[['e'], ['b'], ['c']]\n",
      "[['e'], ['c'], ['b']]\n",
      "[['e'], ['f'], ['b']]\n",
      "[['e'], ['f'], ['c']]\n",
      "[['e'], ['f'], ['c'], ['b']]\n",
      "f 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['f']]\n",
      "[['f'], ['b']]\n",
      "[['f'], ['c']]\n",
      "[['f'], ['b'], ['c']]\n",
      "[['f'], ['c'], ['b']]\n"
     ]
    }
   ],
   "source": [
    "import copy     #用与深拷贝\n",
    "\n",
    "def getElem(dataList):      #求出这个数据集的所有不同的元素\n",
    "    elem = []\n",
    "    for i in dataList[:]:\n",
    "        for j in i[:]:\n",
    "            for k in j[:]:\n",
    "                if k not in elem:       #这个元素没有出现过，就添加如这个列表\n",
    "                    elem.append(k)\n",
    "\n",
    "    elem = sorted(elem)     #排序\n",
    "    #print(elem)\n",
    "    return elem\n",
    "\n",
    "def deleteNotFreElem(data, notFreElem):     #从数据集中删除出现次数不频繁的元素\n",
    "    if len(notFreElem) == 0:\n",
    "        return\n",
    "\n",
    "    for i in data[:]:\n",
    "        for j in i[:]:\n",
    "            for k in j[:]:\n",
    "                if k in notFreElem:\n",
    "                    x = data.index(i)\n",
    "                    y = i.index(j)\n",
    "                    z = j.index(k)          #上面3行，获取这个元素所在的位置\n",
    "                    data[ x ][ y ].remove(k)        #获取到位置后，移除这个不频繁的元素\n",
    "        while [] in i:\n",
    "            i.remove([])       #要是删除后，某个项变为空列表，就删除这个空列表\n",
    "    while [] in data:\n",
    "        data.remove([])        #要是删除后，某个项变为空列表，就删除这个空列表\n",
    "\n",
    "    #print(data)\n",
    "    return\n",
    "\n",
    "def getPrefixData(e, data): #得到前缀投影的数据库\n",
    "    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n",
    "                                  #浅拷贝copy  只是地址不同，但一个变化，另一个可能会变化？在这个里面是\n",
    "                                                #若列表里全是不可变元素，则浅拷贝和深拷贝差不多\n",
    "    flage = 0 #一个标志变量                     #但若列表里包含可变元素，如字典，多维列表，等，那浅拷贝就不合适了，得用深拷贝\n",
    "    for i in copyData[:]:\n",
    "        for j in i[:]:\n",
    "            for k in j[:]:\n",
    "                if len(j) <= 1:     #如果这一行的某一个项，只有 1 个元素，若不相等直接去除就是了\n",
    "                    if e != k:\n",
    "                        j.remove(k)     #如果不是e就移除，直到 k==e 时，停止\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        flage = 1   #一个标志变量，如果 k==e ，则设置为 1 ，此时退出循环，加入 下一条 数据，去除它的前缀\n",
    "                        break\n",
    "                else:\n",
    "                    if e != k:\n",
    "                        j.remove(k)\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        j[0] = '_'+j[0]         #这一行的某一个项的元素个数不是1个，当 k==e 时，去掉k，并且要在前面加下划线 ‘_’\n",
    "                        flage = 1\n",
    "                        break\n",
    "            while [] in i:\n",
    "                i.remove([])    #在求后缀过程中，某个项集成了空，就删除这个空的，别让它占位置\n",
    "\n",
    "            if flage == 1:\n",
    "                flage = 0       #进入下一条数据时，要把它置0\n",
    "                break\n",
    "    while [] in copyData:\n",
    "        copyData.remove([])             #在求后缀过程中，某个项集成了空，就删除这个空的，别让它占位置\n",
    "    #print(copyData)\n",
    "    return copyData\n",
    "\n",
    "#得到elem中每个元素的新的数据集，（就是在这个dataList数据集中，依次去掉每个元素，形成的新的数据集，为了递归往下挖掘）\n",
    "def getAllPrefixData( elem, prefixE, dataList):\n",
    "    data1 = list(copy.deepcopy(dataList))   #深拷贝一封数据集\n",
    "    allPrefixData = []  #是一个四维列表，每一列都是在原来的数据集中，去除prefixE这个前缀后形成的新的数据集\n",
    "\n",
    "    for e in elem:\n",
    "        if set('_').issubset(e):        #  例如 _e 和 e 可不是同一个元素，要分开讨论\n",
    "            temp = useCycleGetPrefixData(e, prefixE, data1)\n",
    "            allPrefixData.append(temp)\n",
    "        else:\n",
    "            temp2 = getPrefixData( e,data1)\n",
    "            allPrefixData.append( temp2 )   #求出 e 的后缀数据库后，加入这个类别\n",
    "\n",
    "    return allPrefixData\n",
    "\n",
    "#求某个前缀的 频繁元素 与 非频繁元素\n",
    "def useCycleGetFreElem(dataList, prefixE, elem, minsup):     #如果是第一次循环，没有前缀，那么 prefixE就置为 -1\n",
    "\n",
    "    elemsup = {}    #存放每个不同元素的出现次数，要尤其注意 _e  和 e 的区别\n",
    "    for e in elem:\n",
    "        for i in dataList[:]:\n",
    "            for j in i:\n",
    "                if set('_').issubset(e):      #  _e  和 e 的区别，   想想下划线是怎么来的，就是某个项集有2个元素及以上时，前缀字母删除后，加的下划线，这个下划线其实就是这个前缀字母\n",
    "                    temp = e[1]\n",
    "                    if set([prefixE, temp]).issubset(set(j)):   #当有下划线时，要格外注意，这个时候对 _e 计数，要看当前字面上一个元素是不是前缀元素，如果是，_e加1\n",
    "                        elemsup[e] = elemsup.get(e, 0) + 1\n",
    "                if e in j:\n",
    "                    elemsup[e] = elemsup.get(e, 0) + 1\n",
    "                    break\n",
    "    #print(elemsup)\n",
    "    freElem = []\n",
    "    notFreElem = []\n",
    "    for i in elemsup.keys():\n",
    "        if elemsup[i] >= minsup:    #分辨频繁元素和非频繁元素\n",
    "            freElem.append(i)\n",
    "        else:\n",
    "            notFreElem.append(i)\n",
    "    #print(freElem)\n",
    "    #print(elemsup)\n",
    "    return freElem, notFreElem\n",
    "\n",
    "def useCycleGetPrefixData(e,prefixE, data):  #这个是在带前缀的情况下，求某元素的投影\n",
    "    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n",
    "\n",
    "    flage = 0   #标志变量，如果为1，表示循环要进入下一条数据记录\n",
    "    for i in copyData[:]:\n",
    "        for j in i[:]:\n",
    "            if set('_').issubset(e):\n",
    "                if set([prefixE, e[1]]).issubset(set(j)):   #下划线本来就是一个占位符，表示前缀字母，现在又变回来了了\n",
    "                    for l in j[:]:\n",
    "                        if (l == prefixE) or (l == e[1]):   #如果这个 两个字母 整体 在这个项集里，就把这个整体都移除，形成下一个前缀的投影，也就是新的数据记录\n",
    "                            j.remove(l)\n",
    "                    break\n",
    "            for k in j[:]:\n",
    "                if len(j) <= 1:\n",
    "                    if e != k:\n",
    "                        j.remove(k)\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        flage = 1\n",
    "                        break\n",
    "                else:\n",
    "                    if e != k:\n",
    "                        j.remove(k)\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        j[0] = '_'+j[0]\n",
    "                        flage = 1\n",
    "                        break\n",
    "            while [] in i:\n",
    "                i.remove([])\n",
    "\n",
    "            if flage == 1:\n",
    "                flage = 0\n",
    "                break\n",
    "    while [] in copyData:\n",
    "        copyData.remove([])\n",
    "    #print(copyData)\n",
    "    return copyData\n",
    "\n",
    "\n",
    "def cycleGetFreElem(preFixData, e, minsup):     #递归调用，求出频繁序列\n",
    "    copyPreFixData = list(copy.deepcopy(preFixData))\n",
    "    allFreSequence = [  ]    #存放这个项集的所有频繁序列,然后返回\n",
    "\n",
    "    allElem = getElem(copyPreFixData)  #返回所有 单个 元素\n",
    "    #print(allElem)\n",
    "    freElem, notFreElem = useCycleGetFreElem(copyPreFixData, e, allElem, minsup)    #求某个前缀数据库的频繁元素，和GetFreElem基本一样，就是多了个参数\n",
    "    #print(freElem, notFreElem)\n",
    "    deleteNotFreElem(copyPreFixData, notFreElem)    #从数据集删除非频繁元素\n",
    "    thisAllPrefixData = getAllPrefixData(freElem, e, copyPreFixData)    #得到这个元素的投影数据库，这个函数是为了循环专用的函数\n",
    "    #print(thisAllPrefixData)\n",
    "\n",
    "    for x in freElem:\n",
    "        if set('_').issubset(set(x)):   #有下划线就把下划线在换为前缀字母，这个整体是在一起的\n",
    "            newElem = [     [e , x[1]]    ]\n",
    "            allFreSequence.append( newElem )    #生成频繁序列\n",
    "        else:\n",
    "            temp2 = [[e],[x]]       #没下划线，就分开放，在同一个序列，但是不在同1个项集\n",
    "            allFreSequence.append( temp2 )      #生成频繁序列，加入\n",
    "\n",
    "    lengthFreElem = len(freElem)\n",
    "    for i in range(lengthFreElem):\n",
    "        temp = cycleGetFreElem(thisAllPrefixData[i], freElem[i], minsup)    #递归调用，求下一个前缀的频繁序列，返回它的频繁序列\n",
    "        for x in temp:  # x 就是表示它的前缀，是一个序列\n",
    "            if set('_').issubset(x[0][0]):      #如果有下划线一定在最前面\n",
    "                t = copy.deepcopy(x)\n",
    "                t[0] = [e , str(t[0][0])[1] ]   #有下划线就把下划线在换为 前缀字母，这个整体是在一起的\n",
    "                allFreSequence.append( t )\n",
    "            else:\n",
    "                t2 = copy.deepcopy(x)\n",
    "                t2.insert(0, [e])   #没有下划线，就把前缀放入第一个位置\n",
    "                allFreSequence.append(t2)\n",
    "\n",
    "        #allFreElem.append(list(temp))\n",
    "    #print(allFreSequence)\n",
    "    return allFreSequence\n",
    "\n",
    "def prefixSpan(dataList, minsup = 2):       #prefixSpan流程\n",
    "    elem = getElem( dataList )  #得到数据集中所有不同的元素\n",
    "    freElem, notFreElem = useCycleGetFreElem(dataList,'-1', elem, minsup)   #返回的是列表，不含支持度,一个是频繁项，一个是非频繁项，没有前缀就把 prefixE这个变量置为-1\n",
    "    #print(freElem, notFreElem)         #  ['a', 'b', 'c', 'd', 'e', 'f'] ['g']\n",
    "    deleteNotFreElem(dataList, notFreElem)      #从数据集中删除不频繁的元素\n",
    "    #print(dataList)\n",
    "    allPrefixData = getAllPrefixData(freElem, '-1' , dataList)      #返回每个频繁元素的后缀数据库，用一个4维列表表示\n",
    "    #print(allPrefixData)\n",
    "\n",
    "    allfreSequence = {}     #收集所有的频繁序列\n",
    "    allListFreSequence = []      #也是收集所有的频繁序列，不过是列表表示，为了输出好看点，特意弄的\n",
    "    lengthFreElem = len(allPrefixData)\n",
    "    for x in range(lengthFreElem):\n",
    "        l = cycleGetFreElem(allPrefixData[x], freElem[x], minsup)   #循环递归，得到频繁序列\n",
    "        l.insert(0, [[freElem[x]]])     #把当前循环的前缀字母放入列表最前面\n",
    "        #print(l)\n",
    "        allfreSequence[freElem[x]] = l\n",
    "        allListFreSequence.append(l)#收集所有的频繁序列，不过是用列表表示，为了输出好看点，特意弄的，当然你可以不用写\n",
    "\n",
    "    for lengthE in range(lengthFreElem):    #这就是一个输出，我为了输出好看一点才加的，嫌麻烦就不用写下面这个循环了\n",
    "        print(freElem[lengthE],'这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>')\n",
    "        for x in allListFreSequence[lengthE]:\n",
    "            print(x)\n",
    "\n",
    "    #print(allfreSequence)\n",
    "    return allfreSequence\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #所用数据库如下\n",
    "    mydata = [\n",
    "        [['a'], ['a', 'b', 'c'], ['a', 'c'], ['d'], ['c', 'f']      ],\n",
    "        [['a', 'd'], ['c'], ['b', 'c'], ['a', 'e']\t\t\t        ],\n",
    "        [['e' ,'f'] , ['a', 'b'], ['d', 'f'] , ['c'] ,['b']\t    ],\n",
    "        [['e'], ['g'] ,['a', 'f'] , ['c'] ,['b'] ,['c']\t\t    ],\n",
    "    ]\n",
    "    minsup = 2\n",
    "    q = prefixSpan( mydata, minsup )\n",
    "\n",
    "    # for x in q:   #输出\n",
    "    #     print(x,'::', q[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 4, 'b': 4, 'c': 4, 'd': 3, 'e': 3, 'f': 3, 'g': 1}\n",
      "{'_b': 2, '_d': 1, '_f': 1, 'a': 2, 'b': 4, 'c': 4, 'd': 2, 'e': 1, 'f': 2}\n",
      "{'a': 1, 'b': 1, 'c': 2, 'd': 2, 'f': 2}\n",
      "{'c': 1, 'd': 1, 'f': 1}\n",
      "{'_f': 1, 'c': 2, 'f': 1}\n",
      "{}\n",
      "{'c': 1}\n",
      "{'_b': 1, 'a': 1, 'c': 1, 'd': 1, 'f': 1}\n",
      "{'_c': 2, 'a': 2, 'c': 2, 'd': 1, 'f': 1}\n",
      "{'a': 2, 'c': 1}\n",
      "{}\n",
      "{'_c': 1, 'c': 1}\n",
      "{'c': 1}\n",
      "{'a': 2, 'b': 3, 'c': 3, 'd': 1, 'f': 1}\n",
      "{'_c': 1, 'c': 1}\n",
      "{'_c': 1, 'a': 1, 'c': 1}\n",
      "{'a': 1, 'c': 1}\n",
      "{'_f': 1, 'b': 1, 'c': 2, 'f': 1}\n",
      "{}\n",
      "{'b': 1, 'c': 1}\n",
      "{'_c': 2, 'a': 2, 'b': 1, 'c': 3, 'd': 2, 'e': 1, 'f': 2}\n",
      "{'a': 2, 'c': 1, 'd': 1, 'f': 1}\n",
      "{}\n",
      "{'_c': 1, 'c': 1, 'd': 1, 'f': 1}\n",
      "{'c': 1, 'd': 1, 'f': 1}\n",
      "{'_f': 1, 'c': 2, 'f': 1}\n",
      "{}\n",
      "{'c': 1}\n",
      "{'a': 2, 'b': 3, 'c': 3, 'd': 1, 'e': 1, 'f': 1}\n",
      "{'_c': 1, 'c': 1}\n",
      "{'_c': 1, 'a': 1, 'c': 1}\n",
      "{'a': 1, 'c': 1}\n",
      "{'_f': 1, 'a': 1, 'b': 2, 'c': 3, 'e': 1, 'f': 1}\n",
      "{'_c': 1}\n",
      "{'b': 2, 'c': 1}\n",
      "{}\n",
      "{'_f': 1, 'a': 2, 'b': 2, 'c': 2, 'd': 1, 'f': 2}\n",
      "{'_b': 1, '_f': 1, 'b': 2, 'c': 2, 'f': 1}\n",
      "{'c': 1}\n",
      "{'b': 2, 'c': 1}\n",
      "{}\n",
      "{'b': 1, 'c': 2, 'f': 1}\n",
      "{}\n",
      "{'b': 2, 'c': 1}\n",
      "{}\n",
      "{'b': 2, 'c': 2}\n",
      "{'c': 1}\n",
      "{'b': 2, 'c': 1}\n",
      "{}\n",
      "{'a': 1, 'b': 2, 'c': 2, 'd': 1, 'f': 1}\n",
      "{'b': 1, 'c': 2}\n",
      "{}\n",
      "{'b': 2, 'c': 1}\n",
      "{}\n",
      "a 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['a']]\n",
      "[['a', 'b']]\n",
      "[['a'], ['a']]\n",
      "[['a'], ['b']]\n",
      "[['a'], ['c']]\n",
      "[['a'], ['d']]\n",
      "[['a'], ['f']]\n",
      "[['a', 'b'], ['c']]\n",
      "[['a', 'b'], ['d']]\n",
      "[['a', 'b'], ['f']]\n",
      "[['a', 'b'], ['d'], ['c']]\n",
      "[['a'], ['b', 'c']]\n",
      "[['a'], ['b'], ['a']]\n",
      "[['a'], ['b'], ['c']]\n",
      "[['a'], ['b', 'c'], ['a']]\n",
      "[['a'], ['c'], ['a']]\n",
      "[['a'], ['c'], ['b']]\n",
      "[['a'], ['c'], ['c']]\n",
      "[['a'], ['d'], ['c']]\n",
      "b 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['b']]\n",
      "[['b', 'c']]\n",
      "[['b'], ['a']]\n",
      "[['b'], ['c']]\n",
      "[['b'], ['d']]\n",
      "[['b'], ['f']]\n",
      "[['b', 'c'], ['a']]\n",
      "[['b'], ['d'], ['c']]\n",
      "c 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['c']]\n",
      "[['c'], ['a']]\n",
      "[['c'], ['b']]\n",
      "[['c'], ['c']]\n",
      "d 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['d']]\n",
      "[['d'], ['b']]\n",
      "[['d'], ['c']]\n",
      "[['d'], ['c'], ['b']]\n",
      "e 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['e']]\n",
      "[['e'], ['a']]\n",
      "[['e'], ['b']]\n",
      "[['e'], ['c']]\n",
      "[['e'], ['f']]\n",
      "[['e'], ['a'], ['b']]\n",
      "[['e'], ['a'], ['c']]\n",
      "[['e'], ['a'], ['c'], ['b']]\n",
      "[['e'], ['b'], ['c']]\n",
      "[['e'], ['c'], ['b']]\n",
      "[['e'], ['f'], ['b']]\n",
      "[['e'], ['f'], ['c']]\n",
      "[['e'], ['f'], ['c'], ['b']]\n",
      "f 这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>\n",
      "[['f']]\n",
      "[['f'], ['b']]\n",
      "[['f'], ['c']]\n",
      "[['f'], ['b'], ['c']]\n",
      "[['f'], ['c'], ['b']]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def getElem(dataList):\n",
    "    \n",
    "    elem = []\n",
    "    for i in dataList:\n",
    "        for j in i[:]:\n",
    "            for k in j[:]:\n",
    "                if k not in elem:\n",
    "                    elem.append(k)\n",
    "    elem = sorted(elem)\n",
    "#     print(elem)\n",
    "    return elem\n",
    "\n",
    "#从数据集中删除出现次数不频繁的元素 \n",
    "def deleteNotFreEleme(data, notFreElem):  \n",
    "   \n",
    "    if len(notFreElem) == 0:\n",
    "        return\n",
    "    \n",
    "    for i in data[:]:\n",
    "        for j in i[:]:\n",
    "            for k in j[:]:\n",
    "                if k in notFreElem:\n",
    "                    x = data.index(i)\n",
    "                    y = i.index(j)\n",
    "                    z = j.index(k)\n",
    "                    data[x][y].remove(k)\n",
    "        while [] in i:\n",
    "            i.remove([])\n",
    "    while [] in data:\n",
    "        data.remove([])\n",
    "#     print(data)\n",
    "    return\n",
    "    \n",
    "def getAllPrefixData(elem, prefixE, dataList):\n",
    "    data1 = list(copy.deepcopy(dataList))  #深度拷贝一封数据集\n",
    "    allPrefixData = []\n",
    "    \n",
    "    for e in elem:\n",
    "        if set('_').issubset(e):\n",
    "            temp = useCycleGetPrefixData(e, prefixE, data1)\n",
    "            allPrefixData.append(temp)\n",
    "        else:\n",
    "            temp2 = getPrefixData(e,data1)\n",
    "            allPrefixData.append(temp2)\n",
    "#     print(allPrefixData)\n",
    "    return allPrefixData\n",
    "    \n",
    "    \n",
    "def useCycleGetFreElem(dataList, prefixE, elem, minsup):\n",
    "    \n",
    "    elemsup = {}\n",
    "    for e in elem:\n",
    "        for i in dataList[:]:\n",
    "            for j in i:\n",
    "                if set('_').issubset(e):\n",
    "                    temp = e[1]\n",
    "                    if set([prefixE,temp]).issubset(set(j)):\n",
    "                        elemsup[e] = elemsup.get(e,0) + 1\n",
    "                if e in j:\n",
    "                    #将所有元素存成字典类型，元素为key，数量为value\n",
    "                    elemsup[e] = elemsup.get(e,0) + 1\n",
    "                    break\n",
    "#     print(elemsup)           \n",
    "    freElem = []\n",
    "    notFrem = []\n",
    "    for i in elemsup.keys():\n",
    "        if elemsup[i] >= minsup:\n",
    "            freElem.append(i)\n",
    "#             print(elemsup[i],i)\n",
    "        else:\n",
    "            notFrem.append(i)\n",
    "    return freElem,notFrem\n",
    "\n",
    "def useCycleGetPrefixData(e,prefixE, data):  #这个是在带前缀的情况下，求某元素的投影\n",
    "    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n",
    "\n",
    "    flage = 0   #标志变量，如果为1，表示循环要进入下一条数据记录\n",
    "    for i in copyData[:]:\n",
    "        for j in i[:]:\n",
    "            if set('_').issubset(e):\n",
    "                if set([prefixE, e[1]]).issubset(set(j)):   #下划线本来就是一个占位符，表示前缀字母，现在又变回来了了\n",
    "                    for l in j[:]:\n",
    "                        if (l == prefixE) or (l == e[1]):   #如果这个 两个字母 整体 在这个项集里，就把这个整体都移除，形成下一个前缀的投影，也就是新的数据记录\n",
    "                            j.remove(l)\n",
    "                    break\n",
    "            for k in j[:]:\n",
    "                if len(j) <= 1:\n",
    "                    if e != k:\n",
    "                        j.remove(k)\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        flage = 1\n",
    "                        break\n",
    "                else:\n",
    "                    if e != k:\n",
    "                        j.remove(k)\n",
    "                    else:\n",
    "                        j.remove(k)\n",
    "                        j[0] = '_'+j[0]\n",
    "                        flage = 1\n",
    "                        break\n",
    "            while [] in i:\n",
    "                i.remove([])\n",
    "\n",
    "            if flage == 1:\n",
    "                flage = 0\n",
    "                break\n",
    "    while [] in copyData:\n",
    "        copyData.remove([])\n",
    "#     print(copyData)\n",
    "    return copyData\n",
    "                       \n",
    "\n",
    "def prefixSpan(dataList, minsup = 2):\n",
    "    elem = getElem(dataList)\n",
    "#     print(elem)\n",
    "    freElem, notFrem = useCycleGetFreElem(dataList, '-1', elem, minsup)\n",
    "#     print(freElem,notFrem)\n",
    "#     print(dataList)\n",
    "    deleteNotFreEleme(dataList,notFrem)  #从数据集中删除不频繁的元素\n",
    "#     print(dataList)\n",
    "    allPrefixData = getAllPrefixData(freElem, '-1', dataList)\n",
    "    \n",
    "    allfreSequence = {}\n",
    "    allListFreSequence = []\n",
    "    lengthFreElem = len(allPrefixData)\n",
    "    for x in range(lengthFreElem):\n",
    "        l = cycleGetFreElem(allPrefixData[x], freElem[x], minsup)\n",
    "        l.insert(0, [[freElem[x]]])\n",
    "#         print(l)\n",
    "        allfreSequence[freElem[x]] = l\n",
    "        allListFreSequence.append(l)\n",
    "    for lengthE in range(lengthFreElem):\n",
    "        print(freElem[lengthE],'这个前缀的，它的频繁序列见下面--------------->>>>>>>>>>')\n",
    "        for x in allListFreSequence[lengthE]:\n",
    "            print(x)\n",
    "#     print(allfreSequence)\n",
    "    return allfreSequence\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mydata = [\n",
    "        [[\"a\"],[\"a\",\"b\",\"c\"],[\"a\",\"c\"],[\"d\"],[\"c\",\"f\"]],\n",
    "        [[\"a\",\"d\"],[\"c\"],[\"b\",\"c\"],[\"a\",\"e\"]],\n",
    "        [[\"e\",\"f\"],[\"a\",\"b\"],[\"d\",\"f\"],[\"c\"],[\"b\"]],\n",
    "        [[\"e\"],[\"g\"],[\"a\",\"f\"],[\"c\"],[\"b\"],[\"c\"]]\n",
    "    ]\n",
    "    minsup = 2\n",
    "    prefixSpan(mydata, minsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
