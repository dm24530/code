{"cells":[{"cell_type":"markdown","metadata":{"id":"nFvZ3OQm_1Sa"},"source":["# 3.3.2Sprk上FP-Growth算法实践"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":1045,"status":"error","timestamp":1614521803910,"user":{"displayName":"狄洺","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhiYdtLRyWxEL5-a0628SLf-QrwCseeizEKVqj=s64","userId":"00101951631288157688"},"user_tz":-480},"id":"ATsKSXcP_1So"},"outputs":[],"source":["from pyspark.mllib.fpm import FPGrowth\n","from pyspark import SparkContext"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekTp373R_84u","outputId":"0f4b1844-6b93-4577-b2df-667ba7ef9f53"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n","\u001b[K     |████████████████████████████████| 204.8MB 63kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 18.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=078fefcf557de262c80b1f59071ef366af561ea8fa430dae9daa650b4a59dfe1\n","  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VytetbH2_1Sp","outputId":"c78d6814-58c0-4286-b8e0-4c25c462f2c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["['牛奶'] : 4\n","['牛奶', '纸尿裤'] : 3\n","['牛奶', '纸尿裤', '奶酪'] : 3\n","['牛奶', '奶酪'] : 4\n","['饮料'] : 4\n","['饮料', '牛奶'] : 3\n","['饮料', '牛奶', '奶酪'] : 3\n","['饮料', '纸尿裤'] : 3\n","['饮料', '奶酪'] : 3\n","['蜂蜜'] : 3\n","['奶酪'] : 5\n","['啤酒'] : 3\n","['啤酒', '纸尿裤'] : 3\n","['纸尿裤'] : 5\n","['纸尿裤', '奶酪'] : 4\n","['面包'] : 4\n","['面包', '牛奶'] : 3\n","['面包', '牛奶', '奶酪'] : 3\n","['面包', '纸尿裤'] : 3\n","['面包', '纸尿裤', '奶酪'] : 3\n","['面包', '奶酪'] : 4\n"]}],"source":["sc = SparkContext(appName='FPGrowth')\n","data = sc.textFile('fpgrowth.txt')\n","transactions = data.map(lambda line:line.strip().split(',')[1:])\n","minSupport = 0.5\n","numPartitions = 2\n","model = FPGrowth.train(transactions,minSupport,numPartitions)\n","result = model.freqItemsets().collect()\n","for fi in result:   \n","    print(str(fi.items).replace('u\\'','\\'').encode('unicode-escape').decode(\"unicode-escape\"),\":\",fi.freq)\n","sc.stop()                               "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6Gk_l-1_1Sq"},"outputs":[],"source":["sc.stop()"]},{"cell_type":"markdown","metadata":{"id":"0xEGIFuc_1Sq"},"source":["# 使用关联规则"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PHtv3zY_1Sr"},"outputs":[],"source":["from pyspark.sql.functions import split\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ue3XllwF_1Sr","outputId":"c57bf6d1-586d-4ac8-838c-8961eadec36b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pyspark.sql.session.SparkSession'\u003e\n"]}],"source":["from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession\n","sc = SparkContext('local')\n","spark = SparkSession(sc)\n","print(type(spark))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZr0mPwB_1Ss","outputId":"ccfbad5e-300a-4ede-95b2-b025e39504a7","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------+\n","|items                                    |\n","+-----------------------------------------+\n","|[1, 饮料, 鸡腿, 蜂蜜, 面包, 牛奶, 奶酪]  |\n","|[2, 面包, 牛奶, 奶酪, 鸡蛋, 纸尿裤, 蜂蜜]|\n","|[3, 啤酒, 纸尿裤, 罐头, 面包, 奶酪, 果酱]|\n","|[4, 啤酒, 纸尿裤, 饮料, 鸡腿, 牛奶, 奶酪]|\n","|[5, 啤酒, 纸尿裤, 饮料, 蜂蜜]            |\n","|[6, 饮料, 纸尿裤, 果酱, 面包, 牛奶, 奶酪]|\n","+-----------------------------------------+\n","\n"]}],"source":["data = (spark.read\n","    .text(\"fpgrowth.txt\")\n","    .select(split(\"value\", \",\").alias(\"items\")))\n","data.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OR9_-oYd_1Ss"},"outputs":[],"source":["sc.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVomE1SR_1St"},"outputs":[],"source":["from pyspark.ml.fpm import FPGrowth\n","from pyspark.sql.functions import split\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYtbXEdt_1St","outputId":"adcea1e1-39fc-46f4-e903-31de00095d12"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----+\n","|               items|freq|\n","+--------------------+----+\n","|              [牛奶]|   4|\n","|      [牛奶, 纸尿裤]|   3|\n","|[牛奶, 纸尿裤, 奶酪]|   3|\n","|        [牛奶, 奶酪]|   4|\n","|              [啤酒]|   3|\n","|      [啤酒, 纸尿裤]|   3|\n","|              [饮料]|   4|\n","|        [饮料, 牛奶]|   3|\n","|  [饮料, 牛奶, 奶酪]|   3|\n","|      [饮料, 纸尿裤]|   3|\n","|        [饮料, 奶酪]|   3|\n","|            [纸尿裤]|   5|\n","|      [纸尿裤, 奶酪]|   4|\n","|              [面包]|   4|\n","|        [面包, 牛奶]|   3|\n","|  [面包, 牛奶, 奶酪]|   3|\n","|      [面包, 纸尿裤]|   3|\n","|[面包, 纸尿裤, 奶酪]|   3|\n","|        [面包, 奶酪]|   4|\n","|              [蜂蜜]|   3|\n","+--------------------+----+\n","only showing top 20 rows\n","\n","+--------------+----------+----------+------------------+\n","|    antecedent|consequent|confidence|              lift|\n","+--------------+----------+----------+------------------+\n","|[纸尿裤, 奶酪]|    [牛奶]|      0.75|             1.125|\n","|[纸尿裤, 奶酪]|    [面包]|      0.75|             1.125|\n","|  [牛奶, 奶酪]|  [纸尿裤]|      0.75|0.8999999999999999|\n","|  [牛奶, 奶酪]|    [饮料]|      0.75|             1.125|\n","|  [牛奶, 奶酪]|    [面包]|      0.75|             1.125|\n","|        [啤酒]|  [纸尿裤]|       1.0|               1.2|\n","|        [饮料]|    [牛奶]|      0.75|             1.125|\n","|        [饮料]|  [纸尿裤]|      0.75|0.8999999999999999|\n","|        [饮料]|    [奶酪]|      0.75|0.8999999999999999|\n","|        [牛奶]|  [纸尿裤]|      0.75|0.8999999999999999|\n","|        [牛奶]|    [奶酪]|       1.0|               1.2|\n","|        [牛奶]|    [饮料]|      0.75|             1.125|\n","|        [牛奶]|    [面包]|      0.75|             1.125|\n","|  [饮料, 奶酪]|    [牛奶]|       1.0|               1.5|\n","|        [面包]|    [牛奶]|      0.75|             1.125|\n","|        [面包]|  [纸尿裤]|      0.75|0.8999999999999999|\n","|        [面包]|    [奶酪]|       1.0|               1.2|\n","|  [面包, 牛奶]|    [奶酪]|       1.0|               1.2|\n","|  [面包, 奶酪]|    [牛奶]|      0.75|             1.125|\n","|  [面包, 奶酪]|  [纸尿裤]|      0.75|0.8999999999999999|\n","+--------------+----------+----------+------------------+\n","only showing top 20 rows\n","\n"]}],"source":["sc = SparkContext(appName='FPGrowth')\n","spark = SparkSession(sc)\n","\n","data = (spark.read\n","    .text(\"fpgrowth.txt\")\n","    .select(split(\"value\", \",\").alias(\"items\")))\n","\n","fp = FPGrowth(minSupport=0.5, minConfidence=0.7)\n","fpm = fp.fit(data)\n","fpm.freqItemsets.show()\n","fpm.associationRules.show()\n","sc.stop()"]},{"cell_type":"markdown","metadata":{"id":"daZtU7tl_1Su"},"source":["# P83有关天气情况和能否进行户外活动"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7uV78k1_1Su","outputId":"e3ef9176-4606-43b6-bc0c-d21da8be3bc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pyspark.sql.session.SparkSession'\u003e\n"]}],"source":["from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession\n","sc = SparkContext('local')\n","spark = SparkSession(sc)\n","print(type(spark))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z20xUUrm_1Sv","outputId":"792b6366-bbcc-489b-f7db-3c5fe883f879"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------+\n","|items                                  |\n","+---------------------------------------+\n","|[1, sunny, hot, high, FALSE, no]       |\n","|[2, sunny, hot, high, TRUE, no]        |\n","|[3, overcase, hot, high, FALSE, yes]   |\n","|[4, rain, mild, high, FALSE, yes]      |\n","|[5, rain, cool, normal, FALSE, yes]    |\n","|[6, rain, cool, normal, TRUE, no]      |\n","|[7, overcase, cool, normal, TRUE, yes] |\n","|[8, sunny, mild, high, FALSE, no]      |\n","|[9, sunny, cool, normal, FALSE, yes]   |\n","|[10, rain, mild, normal, FALSE, yes]   |\n","|[11, sunny, mild, normal, TRUE, yes]   |\n","|[12, overcase, mild, high, TRUE, yes]  |\n","|[13, overcase, hot, normal, FALSE, yes]|\n","|[14, rain, mild, high, TRUE, no]       |\n","+---------------------------------------+\n","\n"]}],"source":["data = (spark.read\n","    .text(\"weather.txt\")\n","    .select(split(\"value\", \",\").alias(\"items\")))\n","data.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emSwe-ao_1Sv"},"outputs":[],"source":["sc.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1d_HDH6q_1Sv"},"outputs":[],"source":["from pyspark.ml.fpm import FPGrowth\n","from pyspark.sql.functions import split\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxz9iKVz_1Sv","outputId":"5bffba37-d36a-4c4f-939f-59c737ce0ebf"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+\n","|            items|freq|\n","+-----------------+----+\n","|          [sunny]|   5|\n","|    [sunny, high]|   3|\n","|      [sunny, no]|   3|\n","|[sunny, no, high]|   3|\n","|   [sunny, FALSE]|   3|\n","|            [hot]|   4|\n","|      [hot, high]|   3|\n","|     [hot, FALSE]|   3|\n","|           [high]|   7|\n","|    [high, FALSE]|   4|\n","|      [high, yes]|   3|\n","|           [TRUE]|   6|\n","|     [TRUE, high]|   3|\n","|     [TRUE, mild]|   3|\n","|   [TRUE, normal]|   3|\n","|      [TRUE, yes]|   3|\n","|           [mild]|   6|\n","|     [mild, high]|   4|\n","|    [mild, FALSE]|   3|\n","|      [mild, yes]|   4|\n","+-----------------+----+\n","only showing top 20 rows\n","\n","+-----------+----------+-------------------+------------------+\n","| antecedent|consequent|         confidence|              lift|\n","+-----------+----------+-------------------+------------------+\n","|    [FALSE]|   [sunny]|              0.375|             1.125|\n","|    [FALSE]|     [hot]|              0.375|           1.40625|\n","|    [FALSE]|    [high]|                0.5|1.0714285714285714|\n","|    [FALSE]|    [mild]|              0.375|            0.9375|\n","|    [FALSE]|     [yes]|               0.75|              1.25|\n","|    [FALSE]|  [normal]|                0.5|1.0714285714285714|\n","|    [FALSE]|    [rain]|              0.375|             1.125|\n","|[sunny, no]|    [high]|                1.0| 2.142857142857143|\n","|       [no]|   [sunny]|                0.6|               1.8|\n","|       [no]|    [high]|                0.8|1.7142857142857144|\n","|       [no]|    [TRUE]|                0.6|1.4999999999999998|\n","|   [normal]|    [TRUE]|0.42857142857142855|1.0714285714285714|\n","|   [normal]|    [cool]| 0.5714285714285714| 2.142857142857143|\n","|   [normal]|   [FALSE]| 0.5714285714285714|1.0714285714285714|\n","|   [normal]|     [yes]| 0.8571428571428571|1.4285714285714286|\n","|   [normal]|    [rain]|0.42857142857142855|1.2857142857142858|\n","|[rain, yes]|   [FALSE]|                1.0|             1.875|\n","|    [sunny]|    [high]|                0.6|1.2857142857142856|\n","|    [sunny]|      [no]|                0.6|               1.8|\n","|    [sunny]|   [FALSE]|                0.6|             1.125|\n","+-----------+----------+-------------------+------------------+\n","only showing top 20 rows\n","\n"]}],"source":["sc = SparkContext(appName='Weather')\n","spark = SparkSession(sc)\n","\n","data = (spark.read\n","    .text(\"weather.txt\")\n","    .select(split(\"value\", \",\").alias(\"items\")))\n","\n","fp = FPGrowth(minSupport=0.2, minConfidence=0.3)\n","fpm = fp.fit(data)\n","fpm.freqItemsets.show()\n","fpm.associationRules.show()\n","sc.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9Gh3lFS_1Sw"},"outputs":[],"source":["sc.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAadp61F_1Sw"},"outputs":[],"source":["from pyspark.ml.fpm import FPGrowth\n","from pyspark.sql.functions import split\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYcsv4HW_1Sw","outputId":"813f6c6a-7702-4a82-fea6-e3e98d252346","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+----+\n","|            items|freq|\n","+-----------------+----+\n","|          [sunny]|   5|\n","|    [sunny, high]|   3|\n","|      [sunny, no]|   3|\n","|[sunny, no, high]|   3|\n","|   [sunny, FALSE]|   3|\n","|            [hot]|   4|\n","|      [hot, high]|   3|\n","|     [hot, FALSE]|   3|\n","|           [high]|   7|\n","|    [high, FALSE]|   4|\n","|      [high, yes]|   3|\n","|           [TRUE]|   6|\n","|     [TRUE, high]|   3|\n","|     [TRUE, mild]|   3|\n","|   [TRUE, normal]|   3|\n","|      [TRUE, yes]|   3|\n","|           [mild]|   6|\n","|     [mild, high]|   4|\n","|    [mild, FALSE]|   3|\n","|      [mild, yes]|   4|\n","+-----------------+----+\n","only showing top 20 rows\n","\n","+-----------+----------+-------------------+------------------+\n","| antecedent|consequent|         confidence|              lift|\n","+-----------+----------+-------------------+------------------+\n","|    [FALSE]|   [sunny]|              0.375|             1.125|\n","|    [FALSE]|     [hot]|              0.375|           1.40625|\n","|    [FALSE]|    [high]|                0.5|1.0714285714285714|\n","|    [FALSE]|    [mild]|              0.375|            0.9375|\n","|    [FALSE]|     [yes]|               0.75|              1.25|\n","|    [FALSE]|  [normal]|                0.5|1.0714285714285714|\n","|    [FALSE]|    [rain]|              0.375|             1.125|\n","|[sunny, no]|    [high]|                1.0| 2.142857142857143|\n","|       [no]|   [sunny]|                0.6|               1.8|\n","|       [no]|    [high]|                0.8|1.7142857142857144|\n","|       [no]|    [TRUE]|                0.6|1.4999999999999998|\n","|   [normal]|    [TRUE]|0.42857142857142855|1.0714285714285714|\n","|   [normal]|    [cool]| 0.5714285714285714| 2.142857142857143|\n","|   [normal]|   [FALSE]| 0.5714285714285714|1.0714285714285714|\n","|   [normal]|     [yes]| 0.8571428571428571|1.4285714285714286|\n","|   [normal]|    [rain]|0.42857142857142855|1.2857142857142858|\n","|[rain, yes]|   [FALSE]|                1.0|             1.875|\n","|    [sunny]|    [high]|                0.6|1.2857142857142856|\n","|    [sunny]|      [no]|                0.6|               1.8|\n","|    [sunny]|   [FALSE]|                0.6|             1.125|\n","+-----------+----------+-------------------+------------------+\n","only showing top 20 rows\n","\n"]}],"source":["sc = SparkContext(appName='Weather')\n","spark = SparkSession(sc)\n","\n","data = (spark.read\n","    .text(\"weather.txt\")\n","    .select(split(\"value\", \",\").alias(\"items\")))\n","\n","fp = FPGrowth(minSupport=0.2, minConfidence=0.3)\n","fpm = fp.fit(data)\n","fpm.freqItemsets.show()\n","fpm.associationRules.show()\n","sc.stop()"]},{"cell_type":"markdown","metadata":{"id":"JXLW0nav_1Sw"},"source":["# 3.6.2 PrefixSpan算法"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yf3dzk03_1Sx","outputId":"3bbe0b7f-9473-473d-cce8-a86df0f1a44e"},"outputs":[{"name":"stdout","output_type":"stream","text":["FreqSequence(sequence=[['e']], freq=3)\n","FreqSequence(sequence=[['b']], freq=4)\n","FreqSequence(sequence=[['f']], freq=3)\n","FreqSequence(sequence=[['c']], freq=4)\n","FreqSequence(sequence=[['d']], freq=3)\n","FreqSequence(sequence=[['a']], freq=4)\n","FreqSequence(sequence=[['c'], ['b']], freq=3)\n","FreqSequence(sequence=[['c'], ['a']], freq=2)\n","FreqSequence(sequence=[['c'], ['c']], freq=3)\n","FreqSequence(sequence=[['a'], ['b']], freq=4)\n","FreqSequence(sequence=[['a'], ['b', 'c']], freq=2)\n","FreqSequence(sequence=[['a'], ['b', 'c'], ['a']], freq=2)\n","FreqSequence(sequence=[['a'], ['b'], ['a']], freq=2)\n","FreqSequence(sequence=[['a'], ['b'], ['c']], freq=2)\n","FreqSequence(sequence=[['a'], ['a']], freq=2)\n","FreqSequence(sequence=[['a'], ['c']], freq=4)\n","FreqSequence(sequence=[['a'], ['c'], ['b']], freq=3)\n","FreqSequence(sequence=[['a'], ['c'], ['a']], freq=2)\n","FreqSequence(sequence=[['a'], ['c'], ['c']], freq=3)\n","FreqSequence(sequence=[['a'], ['d']], freq=2)\n","FreqSequence(sequence=[['a'], ['d'], ['c']], freq=2)\n","FreqSequence(sequence=[['a'], ['f']], freq=2)\n","FreqSequence(sequence=[['b', 'c']], freq=2)\n","FreqSequence(sequence=[['b', 'c'], ['a']], freq=2)\n","FreqSequence(sequence=[['b', 'a']], freq=2)\n","FreqSequence(sequence=[['b', 'a'], ['c']], freq=2)\n","FreqSequence(sequence=[['b', 'a'], ['d']], freq=2)\n","FreqSequence(sequence=[['b', 'a'], ['d'], ['c']], freq=2)\n","FreqSequence(sequence=[['b', 'a'], ['f']], freq=2)\n","FreqSequence(sequence=[['b'], ['a']], freq=2)\n","FreqSequence(sequence=[['b'], ['c']], freq=3)\n","FreqSequence(sequence=[['b'], ['d']], freq=2)\n","FreqSequence(sequence=[['b'], ['d'], ['c']], freq=2)\n","FreqSequence(sequence=[['b'], ['f']], freq=2)\n","FreqSequence(sequence=[['e'], ['b']], freq=2)\n","FreqSequence(sequence=[['e'], ['b'], ['c']], freq=2)\n","FreqSequence(sequence=[['e'], ['a']], freq=2)\n","FreqSequence(sequence=[['e'], ['a'], ['b']], freq=2)\n","FreqSequence(sequence=[['e'], ['a'], ['c']], freq=2)\n","FreqSequence(sequence=[['e'], ['a'], ['c'], ['b']], freq=2)\n","FreqSequence(sequence=[['e'], ['c']], freq=2)\n","FreqSequence(sequence=[['e'], ['c'], ['b']], freq=2)\n","FreqSequence(sequence=[['e'], ['f']], freq=2)\n","FreqSequence(sequence=[['e'], ['f'], ['b']], freq=2)\n","FreqSequence(sequence=[['e'], ['f'], ['c']], freq=2)\n","FreqSequence(sequence=[['e'], ['f'], ['c'], ['b']], freq=2)\n","FreqSequence(sequence=[['f'], ['b']], freq=2)\n","FreqSequence(sequence=[['f'], ['b'], ['c']], freq=2)\n","FreqSequence(sequence=[['f'], ['c']], freq=2)\n","FreqSequence(sequence=[['f'], ['c'], ['b']], freq=2)\n","FreqSequence(sequence=[['d'], ['b']], freq=2)\n","FreqSequence(sequence=[['d'], ['c']], freq=3)\n","FreqSequence(sequence=[['d'], ['c'], ['b']], freq=2)\n"]}],"source":["from pyspark.mllib.fpm import PrefixSpan\n","from pyspark import SparkContext\n","if __name__ == \"__main__\":\n","    data = [\n","        [[\"a\"],[\"a\",\"b\",\"c\"],[\"a\",\"c\"],[\"d\"],[\"c\",\"f\"]],\n","        [[\"a\",\"d\"],[\"c\"],[\"b\",\"c\"],[\"a\",\"e\"]],\n","        [[\"e\",\"f\"],[\"a\",\"b\"],[\"d\",\"f\"],[\"c\"],[\"b\"]],\n","        [[\"e\"],[\"g\"],[\"a\",\"f\"],[\"c\"],[\"b\"],[\"c\"]]\n","    ]\n","    sc = SparkContext()\n","    rdd = sc.parallelize(data,2)\n","    model = PrefixSpan.train(rdd, 0.5, 4)\n","    result = (model.freqSequences().collect())\n","    sorted(result)\n","    for fi in result:\n","        print(fi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pM7Nen4_1Sx","outputId":"2c2b6b6d-a4ca-4207-8c94-0cf3e66d5c02"},"outputs":[{"name":"stdout","output_type":"stream","text":["a 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['a']]\n","[['a', 'b']]\n","[['a'], ['a']]\n","[['a'], ['b']]\n","[['a'], ['c']]\n","[['a'], ['d']]\n","[['a'], ['f']]\n","[['a', 'b'], ['c']]\n","[['a', 'b'], ['d']]\n","[['a', 'b'], ['f']]\n","[['a', 'b'], ['d'], ['c']]\n","[['a'], ['b', 'c']]\n","[['a'], ['b'], ['a']]\n","[['a'], ['b'], ['c']]\n","[['a'], ['b', 'c'], ['a']]\n","[['a'], ['c'], ['a']]\n","[['a'], ['c'], ['b']]\n","[['a'], ['c'], ['c']]\n","[['a'], ['d'], ['c']]\n","b 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['b']]\n","[['b', 'c']]\n","[['b'], ['a']]\n","[['b'], ['c']]\n","[['b'], ['d']]\n","[['b'], ['f']]\n","[['b', 'c'], ['a']]\n","[['b'], ['d'], ['c']]\n","c 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['c']]\n","[['c'], ['a']]\n","[['c'], ['b']]\n","[['c'], ['c']]\n","d 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['d']]\n","[['d'], ['b']]\n","[['d'], ['c']]\n","[['d'], ['c'], ['b']]\n","e 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['e']]\n","[['e'], ['a']]\n","[['e'], ['b']]\n","[['e'], ['c']]\n","[['e'], ['f']]\n","[['e'], ['a'], ['b']]\n","[['e'], ['a'], ['c']]\n","[['e'], ['a'], ['c'], ['b']]\n","[['e'], ['b'], ['c']]\n","[['e'], ['c'], ['b']]\n","[['e'], ['f'], ['b']]\n","[['e'], ['f'], ['c']]\n","[['e'], ['f'], ['c'], ['b']]\n","f 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['f']]\n","[['f'], ['b']]\n","[['f'], ['c']]\n","[['f'], ['b'], ['c']]\n","[['f'], ['c'], ['b']]\n"]}],"source":["import copy     #用与深拷贝\n","\n","def getElem(dataList):      #求出这个数据集的所有不同的元素\n","    elem = []\n","    for i in dataList[:]:\n","        for j in i[:]:\n","            for k in j[:]:\n","                if k not in elem:       #这个元素没有出现过，就添加如这个列表\n","                    elem.append(k)\n","\n","    elem = sorted(elem)     #排序\n","    #print(elem)\n","    return elem\n","\n","def deleteNotFreElem(data, notFreElem):     #从数据集中删除出现次数不频繁的元素\n","    if len(notFreElem) == 0:\n","        return\n","\n","    for i in data[:]:\n","        for j in i[:]:\n","            for k in j[:]:\n","                if k in notFreElem:\n","                    x = data.index(i)\n","                    y = i.index(j)\n","                    z = j.index(k)          #上面3行，获取这个元素所在的位置\n","                    data[ x ][ y ].remove(k)        #获取到位置后，移除这个不频繁的元素\n","        while [] in i:\n","            i.remove([])       #要是删除后，某个项变为空列表，就删除这个空列表\n","    while [] in data:\n","        data.remove([])        #要是删除后，某个项变为空列表，就删除这个空列表\n","\n","    #print(data)\n","    return\n","\n","def getPrefixData(e, data): #得到前缀投影的数据库\n","    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n","                                  #浅拷贝copy  只是地址不同，但一个变化，另一个可能会变化？在这个里面是\n","                                                #若列表里全是不可变元素，则浅拷贝和深拷贝差不多\n","    flage = 0 #一个标志变量                     #但若列表里包含可变元素，如字典，多维列表，等，那浅拷贝就不合适了，得用深拷贝\n","    for i in copyData[:]:\n","        for j in i[:]:\n","            for k in j[:]:\n","                if len(j) \u003c= 1:     #如果这一行的某一个项，只有 1 个元素，若不相等直接去除就是了\n","                    if e != k:\n","                        j.remove(k)     #如果不是e就移除，直到 k==e 时，停止\n","                    else:\n","                        j.remove(k)\n","                        flage = 1   #一个标志变量，如果 k==e ，则设置为 1 ，此时退出循环，加入 下一条 数据，去除它的前缀\n","                        break\n","                else:\n","                    if e != k:\n","                        j.remove(k)\n","                    else:\n","                        j.remove(k)\n","                        j[0] = '_'+j[0]         #这一行的某一个项的元素个数不是1个，当 k==e 时，去掉k，并且要在前面加下划线 ‘_’\n","                        flage = 1\n","                        break\n","            while [] in i:\n","                i.remove([])    #在求后缀过程中，某个项集成了空，就删除这个空的，别让它占位置\n","\n","            if flage == 1:\n","                flage = 0       #进入下一条数据时，要把它置0\n","                break\n","    while [] in copyData:\n","        copyData.remove([])             #在求后缀过程中，某个项集成了空，就删除这个空的，别让它占位置\n","    #print(copyData)\n","    return copyData\n","\n","#得到elem中每个元素的新的数据集，（就是在这个dataList数据集中，依次去掉每个元素，形成的新的数据集，为了递归往下挖掘）\n","def getAllPrefixData( elem, prefixE, dataList):\n","    data1 = list(copy.deepcopy(dataList))   #深拷贝一封数据集\n","    allPrefixData = []  #是一个四维列表，每一列都是在原来的数据集中，去除prefixE这个前缀后形成的新的数据集\n","\n","    for e in elem:\n","        if set('_').issubset(e):        #  例如 _e 和 e 可不是同一个元素，要分开讨论\n","            temp = useCycleGetPrefixData(e, prefixE, data1)\n","            allPrefixData.append(temp)\n","        else:\n","            temp2 = getPrefixData( e,data1)\n","            allPrefixData.append( temp2 )   #求出 e 的后缀数据库后，加入这个类别\n","\n","    return allPrefixData\n","\n","#求某个前缀的 频繁元素 与 非频繁元素\n","def useCycleGetFreElem(dataList, prefixE, elem, minsup):     #如果是第一次循环，没有前缀，那么 prefixE就置为 -1\n","\n","    elemsup = {}    #存放每个不同元素的出现次数，要尤其注意 _e  和 e 的区别\n","    for e in elem:\n","        for i in dataList[:]:\n","            for j in i:\n","                if set('_').issubset(e):      #  _e  和 e 的区别，   想想下划线是怎么来的，就是某个项集有2个元素及以上时，前缀字母删除后，加的下划线，这个下划线其实就是这个前缀字母\n","                    temp = e[1]\n","                    if set([prefixE, temp]).issubset(set(j)):   #当有下划线时，要格外注意，这个时候对 _e 计数，要看当前字面上一个元素是不是前缀元素，如果是，_e加1\n","                        elemsup[e] = elemsup.get(e, 0) + 1\n","                if e in j:\n","                    elemsup[e] = elemsup.get(e, 0) + 1\n","                    break\n","    #print(elemsup)\n","    freElem = []\n","    notFreElem = []\n","    for i in elemsup.keys():\n","        if elemsup[i] \u003e= minsup:    #分辨频繁元素和非频繁元素\n","            freElem.append(i)\n","        else:\n","            notFreElem.append(i)\n","    #print(freElem)\n","    #print(elemsup)\n","    return freElem, notFreElem\n","\n","def useCycleGetPrefixData(e,prefixE, data):  #这个是在带前缀的情况下，求某元素的投影\n","    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n","\n","    flage = 0   #标志变量，如果为1，表示循环要进入下一条数据记录\n","    for i in copyData[:]:\n","        for j in i[:]:\n","            if set('_').issubset(e):\n","                if set([prefixE, e[1]]).issubset(set(j)):   #下划线本来就是一个占位符，表示前缀字母，现在又变回来了了\n","                    for l in j[:]:\n","                        if (l == prefixE) or (l == e[1]):   #如果这个 两个字母 整体 在这个项集里，就把这个整体都移除，形成下一个前缀的投影，也就是新的数据记录\n","                            j.remove(l)\n","                    break\n","            for k in j[:]:\n","                if len(j) \u003c= 1:\n","                    if e != k:\n","                        j.remove(k)\n","                    else:\n","                        j.remove(k)\n","                        flage = 1\n","                        break\n","                else:\n","                    if e != k:\n","                        j.remove(k)\n","                    else:\n","                        j.remove(k)\n","                        j[0] = '_'+j[0]\n","                        flage = 1\n","                        break\n","            while [] in i:\n","                i.remove([])\n","\n","            if flage == 1:\n","                flage = 0\n","                break\n","    while [] in copyData:\n","        copyData.remove([])\n","    #print(copyData)\n","    return copyData\n","\n","\n","def cycleGetFreElem(preFixData, e, minsup):     #递归调用，求出频繁序列\n","    copyPreFixData = list(copy.deepcopy(preFixData))\n","    allFreSequence = [  ]    #存放这个项集的所有频繁序列,然后返回\n","\n","    allElem = getElem(copyPreFixData)  #返回所有 单个 元素\n","    #print(allElem)\n","    freElem, notFreElem = useCycleGetFreElem(copyPreFixData, e, allElem, minsup)    #求某个前缀数据库的频繁元素，和GetFreElem基本一样，就是多了个参数\n","    #print(freElem, notFreElem)\n","    deleteNotFreElem(copyPreFixData, notFreElem)    #从数据集删除非频繁元素\n","    thisAllPrefixData = getAllPrefixData(freElem, e, copyPreFixData)    #得到这个元素的投影数据库，这个函数是为了循环专用的函数\n","    #print(thisAllPrefixData)\n","\n","    for x in freElem:\n","        if set('_').issubset(set(x)):   #有下划线就把下划线在换为前缀字母，这个整体是在一起的\n","            newElem = [     [e , x[1]]    ]\n","            allFreSequence.append( newElem )    #生成频繁序列\n","        else:\n","            temp2 = [[e],[x]]       #没下划线，就分开放，在同一个序列，但是不在同1个项集\n","            allFreSequence.append( temp2 )      #生成频繁序列，加入\n","\n","    lengthFreElem = len(freElem)\n","    for i in range(lengthFreElem):\n","        temp = cycleGetFreElem(thisAllPrefixData[i], freElem[i], minsup)    #递归调用，求下一个前缀的频繁序列，返回它的频繁序列\n","        for x in temp:  # x 就是表示它的前缀，是一个序列\n","            if set('_').issubset(x[0][0]):      #如果有下划线一定在最前面\n","                t = copy.deepcopy(x)\n","                t[0] = [e , str(t[0][0])[1] ]   #有下划线就把下划线在换为 前缀字母，这个整体是在一起的\n","                allFreSequence.append( t )\n","            else:\n","                t2 = copy.deepcopy(x)\n","                t2.insert(0, [e])   #没有下划线，就把前缀放入第一个位置\n","                allFreSequence.append(t2)\n","\n","        #allFreElem.append(list(temp))\n","    #print(allFreSequence)\n","    return allFreSequence\n","\n","def prefixSpan(dataList, minsup = 2):       #prefixSpan流程\n","    elem = getElem( dataList )  #得到数据集中所有不同的元素\n","    freElem, notFreElem = useCycleGetFreElem(dataList,'-1', elem, minsup)   #返回的是列表，不含支持度,一个是频繁项，一个是非频繁项，没有前缀就把 prefixE这个变量置为-1\n","    #print(freElem, notFreElem)         #  ['a', 'b', 'c', 'd', 'e', 'f'] ['g']\n","    deleteNotFreElem(dataList, notFreElem)      #从数据集中删除不频繁的元素\n","    #print(dataList)\n","    allPrefixData = getAllPrefixData(freElem, '-1' , dataList)      #返回每个频繁元素的后缀数据库，用一个4维列表表示\n","    #print(allPrefixData)\n","\n","    allfreSequence = {}     #收集所有的频繁序列\n","    allListFreSequence = []      #也是收集所有的频繁序列，不过是列表表示，为了输出好看点，特意弄的\n","    lengthFreElem = len(allPrefixData)\n","    for x in range(lengthFreElem):\n","        l = cycleGetFreElem(allPrefixData[x], freElem[x], minsup)   #循环递归，得到频繁序列\n","        l.insert(0, [[freElem[x]]])     #把当前循环的前缀字母放入列表最前面\n","        #print(l)\n","        allfreSequence[freElem[x]] = l\n","        allListFreSequence.append(l)#收集所有的频繁序列，不过是用列表表示，为了输出好看点，特意弄的，当然你可以不用写\n","\n","    for lengthE in range(lengthFreElem):    #这就是一个输出，我为了输出好看一点才加的，嫌麻烦就不用写下面这个循环了\n","        print(freElem[lengthE],'这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e')\n","        for x in allListFreSequence[lengthE]:\n","            print(x)\n","\n","    #print(allfreSequence)\n","    return allfreSequence\n","\n","\n","if __name__ == '__main__':\n","\n","    #所用数据库如下\n","    mydata = [\n","        [['a'], ['a', 'b', 'c'], ['a', 'c'], ['d'], ['c', 'f']      ],\n","        [['a', 'd'], ['c'], ['b', 'c'], ['a', 'e']\t\t\t        ],\n","        [['e' ,'f'] , ['a', 'b'], ['d', 'f'] , ['c'] ,['b']\t    ],\n","        [['e'], ['g'] ,['a', 'f'] , ['c'] ,['b'] ,['c']\t\t    ],\n","    ]\n","    minsup = 2\n","    q = prefixSpan( mydata, minsup )\n","\n","    # for x in q:   #输出\n","    #     print(x,'::', q[x])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7_mJ0jl_1S2","outputId":"039a8b85-f778-4faf-ecfd-cbae0bb07de9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'a': 4, 'b': 4, 'c': 4, 'd': 3, 'e': 3, 'f': 3, 'g': 1}\n","{'_b': 2, '_d': 1, '_f': 1, 'a': 2, 'b': 4, 'c': 4, 'd': 2, 'e': 1, 'f': 2}\n","{'a': 1, 'b': 1, 'c': 2, 'd': 2, 'f': 2}\n","{'c': 1, 'd': 1, 'f': 1}\n","{'_f': 1, 'c': 2, 'f': 1}\n","{}\n","{'c': 1}\n","{'_b': 1, 'a': 1, 'c': 1, 'd': 1, 'f': 1}\n","{'_c': 2, 'a': 2, 'c': 2, 'd': 1, 'f': 1}\n","{'a': 2, 'c': 1}\n","{}\n","{'_c': 1, 'c': 1}\n","{'c': 1}\n","{'a': 2, 'b': 3, 'c': 3, 'd': 1, 'f': 1}\n","{'_c': 1, 'c': 1}\n","{'_c': 1, 'a': 1, 'c': 1}\n","{'a': 1, 'c': 1}\n","{'_f': 1, 'b': 1, 'c': 2, 'f': 1}\n","{}\n","{'b': 1, 'c': 1}\n","{'_c': 2, 'a': 2, 'b': 1, 'c': 3, 'd': 2, 'e': 1, 'f': 2}\n","{'a': 2, 'c': 1, 'd': 1, 'f': 1}\n","{}\n","{'_c': 1, 'c': 1, 'd': 1, 'f': 1}\n","{'c': 1, 'd': 1, 'f': 1}\n","{'_f': 1, 'c': 2, 'f': 1}\n","{}\n","{'c': 1}\n","{'a': 2, 'b': 3, 'c': 3, 'd': 1, 'e': 1, 'f': 1}\n","{'_c': 1, 'c': 1}\n","{'_c': 1, 'a': 1, 'c': 1}\n","{'a': 1, 'c': 1}\n","{'_f': 1, 'a': 1, 'b': 2, 'c': 3, 'e': 1, 'f': 1}\n","{'_c': 1}\n","{'b': 2, 'c': 1}\n","{}\n","{'_f': 1, 'a': 2, 'b': 2, 'c': 2, 'd': 1, 'f': 2}\n","{'_b': 1, '_f': 1, 'b': 2, 'c': 2, 'f': 1}\n","{'c': 1}\n","{'b': 2, 'c': 1}\n","{}\n","{'b': 1, 'c': 2, 'f': 1}\n","{}\n","{'b': 2, 'c': 1}\n","{}\n","{'b': 2, 'c': 2}\n","{'c': 1}\n","{'b': 2, 'c': 1}\n","{}\n","{'a': 1, 'b': 2, 'c': 2, 'd': 1, 'f': 1}\n","{'b': 1, 'c': 2}\n","{}\n","{'b': 2, 'c': 1}\n","{}\n","a 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['a']]\n","[['a', 'b']]\n","[['a'], ['a']]\n","[['a'], ['b']]\n","[['a'], ['c']]\n","[['a'], ['d']]\n","[['a'], ['f']]\n","[['a', 'b'], ['c']]\n","[['a', 'b'], ['d']]\n","[['a', 'b'], ['f']]\n","[['a', 'b'], ['d'], ['c']]\n","[['a'], ['b', 'c']]\n","[['a'], ['b'], ['a']]\n","[['a'], ['b'], ['c']]\n","[['a'], ['b', 'c'], ['a']]\n","[['a'], ['c'], ['a']]\n","[['a'], ['c'], ['b']]\n","[['a'], ['c'], ['c']]\n","[['a'], ['d'], ['c']]\n","b 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['b']]\n","[['b', 'c']]\n","[['b'], ['a']]\n","[['b'], ['c']]\n","[['b'], ['d']]\n","[['b'], ['f']]\n","[['b', 'c'], ['a']]\n","[['b'], ['d'], ['c']]\n","c 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['c']]\n","[['c'], ['a']]\n","[['c'], ['b']]\n","[['c'], ['c']]\n","d 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['d']]\n","[['d'], ['b']]\n","[['d'], ['c']]\n","[['d'], ['c'], ['b']]\n","e 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['e']]\n","[['e'], ['a']]\n","[['e'], ['b']]\n","[['e'], ['c']]\n","[['e'], ['f']]\n","[['e'], ['a'], ['b']]\n","[['e'], ['a'], ['c']]\n","[['e'], ['a'], ['c'], ['b']]\n","[['e'], ['b'], ['c']]\n","[['e'], ['c'], ['b']]\n","[['e'], ['f'], ['b']]\n","[['e'], ['f'], ['c']]\n","[['e'], ['f'], ['c'], ['b']]\n","f 这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n","[['f']]\n","[['f'], ['b']]\n","[['f'], ['c']]\n","[['f'], ['b'], ['c']]\n","[['f'], ['c'], ['b']]\n"]}],"source":["import copy\n","\n","def getElem(dataList):\n","    \n","    elem = []\n","    for i in dataList:\n","        for j in i[:]:\n","            for k in j[:]:\n","                if k not in elem:\n","                    elem.append(k)\n","    elem = sorted(elem)\n","#     print(elem)\n","    return elem\n","\n","#从数据集中删除出现次数不频繁的元素 \n","def deleteNotFreEleme(data, notFreElem):  \n","   \n","    if len(notFreElem) == 0:\n","        return\n","    \n","    for i in data[:]:\n","        for j in i[:]:\n","            for k in j[:]:\n","                if k in notFreElem:\n","                    x = data.index(i)\n","                    y = i.index(j)\n","                    z = j.index(k)\n","                    data[x][y].remove(k)\n","        while [] in i:\n","            i.remove([])\n","    while [] in data:\n","        data.remove([])\n","#     print(data)\n","    return\n","    \n","def getAllPrefixData(elem, prefixE, dataList):\n","    data1 = list(copy.deepcopy(dataList))  #深度拷贝一封数据集\n","    allPrefixData = []\n","    \n","    for e in elem:\n","        if set('_').issubset(e):\n","            temp = useCycleGetPrefixData(e, prefixE, data1)\n","            allPrefixData.append(temp)\n","        else:\n","            temp2 = getPrefixData(e,data1)\n","            allPrefixData.append(temp2)\n","#     print(allPrefixData)\n","    return allPrefixData\n","    \n","    \n","def useCycleGetFreElem(dataList, prefixE, elem, minsup):\n","    \n","    elemsup = {}\n","    for e in elem:\n","        for i in dataList[:]:\n","            for j in i:\n","                if set('_').issubset(e):\n","                    temp = e[1]\n","                    if set([prefixE,temp]).issubset(set(j)):\n","                        elemsup[e] = elemsup.get(e,0) + 1\n","                if e in j:\n","                    #将所有元素存成字典类型，元素为key，数量为value\n","                    elemsup[e] = elemsup.get(e,0) + 1\n","                    break\n","#     print(elemsup)           \n","    freElem = []\n","    notFrem = []\n","    for i in elemsup.keys():\n","        if elemsup[i] \u003e= minsup:\n","            freElem.append(i)\n","#             print(elemsup[i],i)\n","        else:\n","            notFrem.append(i)\n","    return freElem,notFrem\n","\n","def useCycleGetPrefixData(e,prefixE, data):  #这个是在带前缀的情况下，求某元素的投影\n","    copyData = list(copy.deepcopy(data))    #要用深拷贝deepcopy，深拷贝是创建一块地址，内容和原来一样，但两个完全没联系\n","\n","    flage = 0   #标志变量，如果为1，表示循环要进入下一条数据记录\n","    for i in copyData[:]:\n","        for j in i[:]:\n","            if set('_').issubset(e):\n","                if set([prefixE, e[1]]).issubset(set(j)):   #下划线本来就是一个占位符，表示前缀字母，现在又变回来了了\n","                    for l in j[:]:\n","                        if (l == prefixE) or (l == e[1]):   #如果这个 两个字母 整体 在这个项集里，就把这个整体都移除，形成下一个前缀的投影，也就是新的数据记录\n","                            j.remove(l)\n","                    break\n","            for k in j[:]:\n","                if len(j) \u003c= 1:\n","                    if e != k:\n","                        j.remove(k)\n","                    else:\n","                        j.remove(k)\n","                        flage = 1\n","                        break\n","                else:\n","                    if e != k:\n","                        j.remove(k)\n","                    else:\n","                        j.remove(k)\n","                        j[0] = '_'+j[0]\n","                        flage = 1\n","                        break\n","            while [] in i:\n","                i.remove([])\n","\n","            if flage == 1:\n","                flage = 0\n","                break\n","    while [] in copyData:\n","        copyData.remove([])\n","#     print(copyData)\n","    return copyData\n","                       \n","\n","def prefixSpan(dataList, minsup = 2):\n","    elem = getElem(dataList)\n","#     print(elem)\n","    freElem, notFrem = useCycleGetFreElem(dataList, '-1', elem, minsup)\n","#     print(freElem,notFrem)\n","#     print(dataList)\n","    deleteNotFreEleme(dataList,notFrem)  #从数据集中删除不频繁的元素\n","#     print(dataList)\n","    allPrefixData = getAllPrefixData(freElem, '-1', dataList)\n","    \n","    allfreSequence = {}\n","    allListFreSequence = []\n","    lengthFreElem = len(allPrefixData)\n","    for x in range(lengthFreElem):\n","        l = cycleGetFreElem(allPrefixData[x], freElem[x], minsup)\n","        l.insert(0, [[freElem[x]]])\n","#         print(l)\n","        allfreSequence[freElem[x]] = l\n","        allListFreSequence.append(l)\n","    for lengthE in range(lengthFreElem):\n","        print(freElem[lengthE],'这个前缀的，它的频繁序列见下面---------------\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e')\n","        for x in allListFreSequence[lengthE]:\n","            print(x)\n","#     print(allfreSequence)\n","    return allfreSequence\n","    \n","    \n","if __name__ == '__main__':\n","    mydata = [\n","        [[\"a\"],[\"a\",\"b\",\"c\"],[\"a\",\"c\"],[\"d\"],[\"c\",\"f\"]],\n","        [[\"a\",\"d\"],[\"c\"],[\"b\",\"c\"],[\"a\",\"e\"]],\n","        [[\"e\",\"f\"],[\"a\",\"b\"],[\"d\",\"f\"],[\"c\"],[\"b\"]],\n","        [[\"e\"],[\"g\"],[\"a\",\"f\"],[\"c\"],[\"b\"],[\"c\"]]\n","    ]\n","    minsup = 2\n","    prefixSpan(mydata, minsup)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQ4jEfIt_1S6"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"第三章 关联规则挖掘.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}